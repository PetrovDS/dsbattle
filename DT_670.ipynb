{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PetrovDS\n",
    "Решение с использованием Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"PD-data-train.csv\", sep=\";\", index_col=\"record_id\")\n",
    "test = pd.read_csv(\"PD-data-test.csv\", sep=\";\", index_col=\"record_id\")\n",
    "desc = pd.read_csv(\"PD-data-desc.csv\", sep=\";\")\n",
    "\n",
    "train_raw = train.copy()\n",
    "test_raw = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoding количества сотрудников"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.ul_staff_range = train.ul_staff_range.map({'[1-100]': 'stuff_small','(100-500]': 'stuff_mid','> 500': 'stuff_large'})\n",
    "train = train.join(pd.get_dummies(train.ul_staff_range))\n",
    "train = train.drop([\"ul_staff_range\"], axis=1)\n",
    "\n",
    "test.ul_staff_range = test.ul_staff_range.map({'[1-100]': 'stuff_small','(100-500]': 'stuff_mid','> 500': 'stuff_large'})\n",
    "test = test.join(pd.get_dummies(test.ul_staff_range))\n",
    "test = test.drop([\"ul_staff_range\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиваем на бакеты ul_founders_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def founders_bucket(x):\n",
    "    if x < 4:\n",
    "        return \"fnd_\" + str(x)\n",
    "    if 3 < x < 11:\n",
    "        return \"fnd_4_10\"\n",
    "    if 11 < x < 51:\n",
    "        return \"fnd_11_50\"\n",
    "    if x > 500:\n",
    "        \"fnd_\" + str(x)\n",
    "    return \"fnd_50\"\n",
    "\n",
    "train = train.join(pd.get_dummies(train.ul_founders_cnt.map(lambda x: founders_bucket(x))))\n",
    "train = train.drop([\"ul_founders_cnt\"], axis=1)\n",
    "\n",
    "test = test.join(pd.get_dummies(test.ul_founders_cnt.map(lambda x: founders_bucket(x))))\n",
    "test = test.drop([\"ul_founders_cnt\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уже не помню зачем это, но, видимо, что-то очень важное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.ar_other_profit_and_losses = train.ar_other_profit_and_losses.map(lambda x: 1 if x != 0 else 0)\n",
    "test.ar_other_profit_and_losses = test.ar_other_profit_and_losses.map(lambda x: 1 if x != 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Убираем сразу один лишний признак"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ul_branch_cnt на Test имеет только значения 0\n",
    "train = train.drop([\"ul_branch_cnt\"], axis=1)\n",
    "test = test.drop([\"ul_branch_cnt\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функция, которая возвращает признаки по заданному порогу корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_corr(df, T):\n",
    "    cr = df.corr().dropna(how=\"all\").dropna(axis=1, how=\"all\")\n",
    "    return [col for ind, col in enumerate(cr) if ((cr.iloc[ind,ind+1:] > T) | (cr.iloc[ind,ind+1:] < -T)).any()] + list(set(df.columns) - set(cr.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сама модель, в которой и fit, и predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def DT(df, t_df):\n",
    "    y = df.default_12m\n",
    "    X = df.drop([\"default_12m\"], axis=1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    t_df = scaler.transform(t_df)\n",
    "    \n",
    "    clf = DecisionTreeClassifier(max_depth=None, min_samples_split=300)\n",
    "    print(np.array(cross_val_score(clf, X, y, cv=10)).mean())\n",
    "    \n",
    "    clf.fit(X, y)\n",
    "    return clf.predict_proba(t_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаём копию, дабы не поцарапать первоначальные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train = train.copy()\n",
    "tf_test = test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Делим на два DF: один с заполненными столбцами, второй с пропущенными столбцами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_na = tf_train[tf_train[\"ar_sale_cost\"].isnull()].dropna(axis=1)\n",
    "train_fl = tf_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_na = tf_test[tf_test[\"ar_sale_cost\"].isnull()].dropna(axis=1)\n",
    "test_fl = tf_test.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаляем коррелирующие столбцы. Порог 0.5 получен подбором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col_na = drop_corr(train_na, .5)\n",
    "drop_col_fl = drop_corr(train_fl, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_na = train_na.drop(drop_col_na, axis=1)\n",
    "test_na = test_na.drop(drop_col_na, axis=1)\n",
    "train_fl = train_fl.drop(drop_col_fl, axis=1)\n",
    "test_fl = test_fl.drop(drop_col_fl, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit-predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9521159420289855\n",
      "0.9142952683643528\n"
     ]
    }
   ],
   "source": [
    "y_pred_fl = DT(train_fl, test_fl)\n",
    "y_pred_na = DT(train_na, test_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cutoff выбирается как среднее минус одна сотая. 0.01 получена подгоном С:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8987642980866306"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_c = np.array(list(y_pred_na[:,0]) + list(y_pred_fl[:,0])).mean() - .01\n",
    "T_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Так надо. Правда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_fl = T_c\n",
    "T_na = T_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определяем классы по cuttoff и загоняем ответы в csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_na = pd.DataFrame(zip(list(test_na.index), [0 if i[0] > T_fl else 1 for i in np.array(list(y_pred_na))]), columns=[\"id\", \"predict\"])\n",
    "res_fl = pd.DataFrame(zip(list(test_fl.index), [0 if i[0] > T_na else 1 for i in np.array(list(y_pred_fl))]), columns=[\"id\", \"predict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.concat([res_na, res_fl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(test.columns, axis=1).merge(res, left_index=True, right_on=\"id\").to_csv('PD-submit.csv',index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
